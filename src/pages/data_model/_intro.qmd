## INTRODUCTION

This section explains how we model clinical data across our partner hospitals.

### DATA MODELLING GUIDELINES

NHS hospitals generate vast amounts of electronic data, but it's often unsuitable for immediate analytics or research due to normalisation, transactional design, and inconsistencies across systems. To unify data from various sources, it must be transformed into a Common Data Model (CDM). Extensive transformation risks changing meaning or introducing errors, potentially impacting research outcomes or patient care decisions. This is particularly critical for high-stakes applications like regulatory drug assessments or AI model training for precision medicine. Consequently, we follow strict guidelines to maintain data integrity and trustworthiness throughout our pipelines:

1. **Avoid information loss, enrich data with metadata.** For a given domain of interest, the target data model should not result in any information being lost. Rather, information should be added to enrich understanding of the data item.
2. **Data provenance should always remain visible.** This means that each value or concept, even after transformations, should be tracked back to the source system/table where it was generated.
3. **Source systems and their clinical context should be considered part of the data pipeline.** Source systems and context affect the meaning of data, and while they fall outside control or assurance of engineers, they should be comprehensively documented.      
4. **Data lineage should be traceable back to source, and comparable to source data.** This includes any transformations to numerical values or concepts. 
5. **Standardise structure first, semantics after, and make 'research-ready' only for each use-case.** Data is kept close to source while being made interoperable, and more extensive transformations are performed on the basis of study requirements. How to handle data quality issues in particular should be a decision made at analysis, dependant on type of analysis.  

These guidelines ensure that data is kept as close to its original form for as long as possible, whilst creating syntactic and semantic standardisation, and introducing full visibility over sources and transformations.

### OMOP CDM (GOLD)

The Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) standardises medical data for large-scale analytics and cross-site research. It organizes data into standardised tables and uses consistent vocabulary, enabling syntactic and semantic interoperability, with key advantages:

1. International standard: wide adoption and support has made OMOP the de facto international standard common data model for research;
2. Reproducibility: easier code-sharing and reproduction of research findings across different datasets;
3. Federated analytics: the same code can be directly executed without modification across different sites, with results combined.  

However, OMOP also has limitations:

1. Data model is USA-centric and has elements that are not applicable to other countries, e.g. representation of race and ethnicity;
2. The Standard vocabulary may not capture how standard ontologies are used and updated in other countries, e.g. NHS/UK SNOMED extensions and use of dm+d;   
3. Rigid structure means there is potential information loss during conversion where data, especially of variable quality, must be 'forced' into the model;
4. Different interpretations of how to convert (e.g. choice of source systems, local mappings) may result in OMOP at different sites having varying meaning, unless precise conventions for a particular cohort are agreed in advance;
5. Limited number of fields prevents additional data types or complex medical concepts, e.g. NHS specific qualifiers, and makes it difficult to incorporate new types of data or emerging medical concepts such as genomics and cancer, without workarounds;
6. Representing complex temporal relationships and hierarchical/nested episodes, e.g. cancer pathways, is challenging;
7. Ability to capture data provenance is limited. 

For our work, OMOP serves as a target model for specific cohorts that require interoperable data across multiple sites (i.e. a data mart / Gold layer). However, due to the limitations above, OMOP breaks our guidelines for data integrity and is not used as our primary data model. Rather, we adopt a wider CDM, which we refer to as OMOP Extended (OMOP-EXT CDM), which serves as the Silver layer in a medallion architecture.   

###Â OMOP-EXT CDM (SILVER)







### ROW, TABLE, AND SYSTEMS PROVENANCE

OMOP provides different ways for representing provenance. These include using concepts that represent the [type of data source](https://athena.ohdsi.org/search-terms/terms?domain=Type+Concept&standardConcept=Standard&page=1&pageSize=15&query=), and concepts that represent the [concept status](https://athena.ohdsi.org/search-terms/terms?domain=Condition+Status&standardConcept=Standard&page=1&pageSize=15&query=). "Type" is USA-centric and does not carry granularity to represent the specific types of NHS system (though NHS systems can be mapped to these categories). Concept status is specific to the context in which each condition code was recorded. In practice, this type of metadata is rarely present in NHS source data, and would usually be inferred by the source system. 

In the Common Data Model, SILVER tables therefore include additional columns to enable visibility over the source table, and NHS source system. In addition, in tables where a single row will carry information about a single concept for a single person, it is possible to track this main relationship through to a source row via a row_id that is generated at data ingestion. This enables direct visbility over transformations during the pipeline.
